# SENTIMEMENET

**A Deep Learning Approach for Meme/Non-Meme Classification and Sentiment Analysis in Internet Memes**

CCS 248 Final Project | JZL

---

## üìã Table of Contents

- [Project Overview](#-project-overview)
- [Key Features](#-key-features)
- [Model Architectures & Results](#-model-architectures--results)
- [Dataset Information](#-dataset-information)
- [Installation & Setup](#-installation--setup)
- [How to Set Up the App](#-how-to-set-up-the-app)
- [Usage Guide](#-usage-guide)
- [API Documentation](#-api-documentation)
- [Project Structure](#-project-structure)
- [Technical Documentation](#-technical-documentation)
- [Performance Summary](#-performance-summary)
- [Troubleshooting](#-troubleshooting)
- [License & Credits](#-license--credits)

---

## üéØ Project Overview

**SentimemeNet** is an advanced deep learning system that implements **6 specialized models** for comprehensive meme analysis. The project combines state-of-the-art **image processing** and **text analysis (OCR)** techniques to classify memes across multiple dimensions, providing insights into humor, sentiment, and social context.

### Classification Capabilities

1. **Meme Detection** - Identifies whether an image is a meme or not (92.53% accuracy)
2. **Humour Classification** - Determines if a meme is funny or not funny (52.20% accuracy)
3. **Motivational Classification** - Detects motivational content in memes (61.55% accuracy)
4. **Offensive Classification** - Identifies offensive content in memes (58.58% accuracy)
5. **Sarcasm Classification** - Detects sarcastic elements in memes (55.85% accuracy)
6. **Sentiment Classification** - Analyzes overall sentiment as positive/non-positive (58.10% accuracy)

### Technology Stack

- **Deep Learning Framework:** TensorFlow 2.15.0 / Keras
- **Backend:** Flask (Python 3.8+)
- **Frontend:** HTML5, CSS3, JavaScript (ES6+), Tailwind CSS
- **Computer Vision:** ResNet-based CNN architectures
- **Natural Language Processing:** Bidirectional LSTM with text embeddings
- **OCR Integration:** EasyOCR / Tesseract for text extraction

---

## ‚ú® Key Features

### Deep Learning Models
- ‚úÖ **Multimodal Architecture** - Combines image (CNN) and text (LSTM) processing for sentiment analysis
- ‚úÖ **High-Performance Meme Detection** - 92.53% accuracy with Mini-ResNet architecture
- ‚úÖ **Residual Networks** - Skip connections for better gradient flow and training stability
- ‚úÖ **Advanced Dataset Handling** - Automatic balancing, validation, and filtering
- ‚úÖ **Production-Ready Models** - Saved models with prediction functions and tokenizers

### Web Application
- ‚úÖ **RESTful API** - Flask backend with `/api/analyze_meme` and `/api/health` endpoints
- ‚úÖ **Interactive Frontend** - Drag-and-drop image upload with real-time analysis
- ‚úÖ **OCR Text Input** - Optional manual text input or automatic extraction
- ‚úÖ **Results Visualization** - Confidence scores, progress bars, and color-coded predictions
- ‚úÖ **Export Functionality** - Save analysis results to JSON format
- ‚úÖ **Responsive Design** - Mobile-friendly interface with smooth animations

### Data Processing
- ‚úÖ **Automatic Image Validation** - Pre-validates images before training
- ‚úÖ **Class Balancing** - Prevents bias by equalizing class distributions
- ‚úÖ **Text Preprocessing** - Tokenization with vocabulary management (10,000 words)
- ‚úÖ **Data Augmentation** - Rotation, flip, contrast, zoom for robust training
- ‚úÖ **Multi-Dataset Support** - Combines Excel, CSV, and nested folder structures

---

## üèóÔ∏è Model Architectures & Results

### Model 1: Meme vs. Non-Meme Detection

**Architecture: Mini-ResNet CNN**

```
Input (224√ó224√ó3)
    ‚Üì
Conv2D (32 filters, 3√ó3) + BatchNorm + ReLU
    ‚Üì
6√ó Residual Blocks (32 ‚Üí 64 ‚Üí 128 ‚Üí 256 filters)
    ‚îÇ   ‚îú‚îÄ Conv2D + BatchNorm + ReLU
    ‚îÇ   ‚îú‚îÄ Conv2D + BatchNorm
    ‚îÇ   ‚îî‚îÄ Skip Connection (identity or projection)
    ‚Üì
Global Average Pooling 2D
    ‚Üì
Dense (512 units, ReLU) + Dropout (0.5)
    ‚Üì
Dense (256 units, ReLU) + Dropout (0.5)
    ‚Üì
Output Dense (1 unit, Sigmoid)
```

**Training Strategy:**
- Optimizer: Adam (lr=0.0001)
- Loss: Binary Crossentropy
- Batch Size: 2
- Epochs: 15 with Early Stopping (patience=5)
- Data Augmentation: Rotation (¬±15¬∞), Horizontal Flip, Contrast, Zoom (¬±10%)
- Callbacks: EarlyStopping, ModelCheckpoint

**Results:**

| Metric | Value |
|--------|-------|
| **Test Accuracy** | **92.53%** |
| **Test Loss** | 0.2344 |
| **Precision** | 96.49% |
| **Recall** | 88.49% |
| **F1-Score** | 92.32% |

**Saved Model:** `models/meme_detector_model.h5`

---

### Models 2-6: Sentiment Analysis (Multimodal Architecture)

**Architecture: ResNet-based CNN + Bidirectional LSTM**

```
IMAGE BRANCH                          TEXT BRANCH
Input (224√ó224√ó3)                     Input (Text Sequence, max_len=100)
    ‚Üì                                     ‚Üì
Conv2D (64 filters, 3√ó3)              Embedding Layer (10,000 vocab)
    ‚Üì                                     ‚Üì
4√ó Residual Blocks                    Bidirectional LSTM (128 units)
    ‚îÇ   ‚îú‚îÄ Conv2D + BatchNorm             ‚Üì
    ‚îÇ   ‚îî‚îÄ Skip Connection            Dropout (0.3-0.5)
    ‚Üì                                     ‚Üì
Global Average Pooling                Dense (64 units, ReLU)
    ‚Üì                                     ‚Üì
Dense (128 units, ReLU)               Dense (32 units, ReLU)
    ‚Üì                                     ‚Üì
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚Üì
         Concatenate (Fusion Layer)
                  ‚Üì
         Dense (256 units, ReLU) + Dropout (0.5)
                  ‚Üì
         Dense (128 units, ReLU) + Dropout (0.3)
                  ‚Üì
         Output Dense (1 unit, Sigmoid)
```

**Training Strategy:**
- Optimizer: Adam (lr=0.0001)
- Loss: Binary Crossentropy
- Batch Size: 16
- Epochs: 25 with Early Stopping (patience=3-5)
- Callbacks: EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
- Text Preprocessing: Tokenization, padding to 100 tokens, OOV handling

---

### Model 2: Humour Classification

**Objective:** Determine if a meme is funny or not funny

**Results:**

| Metric | Value |
|--------|-------|
| **Test Accuracy** | 52.20% |
| **Test Loss** | 0.6898 |
| **Precision** | 55.02% |
| **Recall** | 45.02% |
| **F1-Score** | 49.52% |

**Label Mapping:** `funny/very_funny/hilarious ‚Üí Funny` | `not_funny ‚Üí Not Funny`

**Saved Files:** `models/meme_humour_model.h5`, `models/tokenizer_humour.pickle`

---

### Model 3: Motivational Classification

**Objective:** Detect motivational content in memes

**Results:**

| Metric | Value |
|--------|-------|
| **Test Accuracy** | 61.55% |
| **Test Loss** | 0.6766 |
| **Precision** | 61.42% |
| **Recall** | 71.89% |
| **F1-Score** | 66.22% |

**Label Mapping:** `motivational ‚Üí Motivational` | `not_motivational ‚Üí Not Motivational`

**Saved Files:** `models/meme_motivational_model.h5`, `models/tokenizer_motivational.pickle`

---

### Model 4: Offensive Classification

**Objective:** Identify offensive content in memes

**Results:**

| Metric | Value |
|--------|-------|
| **Test Accuracy** | 58.58% |
| **Test Loss** | 0.6922 |
| **Precision** | 57.30% |
| **Recall** | 68.41% |
| **F1-Score** | 62.37% |

**Label Mapping:** `slight/very_offensive/hateful ‚Üí Offensive` | `not_offensive ‚Üí Not Offensive`

**Saved Files:** `models/meme_offensive_model.h5`, `models/tokenizer_offensive.pickle`

---

### Model 5: Sarcasm Classification

**Objective:** Detect sarcastic elements in memes

**Results:**

| Metric | Value |
|--------|-------|
| **Test Accuracy** | 55.85% |
| **Test Loss** | 0.9760 |
| **Precision** | 58.90% |
| **Recall** | 48.35% |
| **F1-Score** | 53.13% |

**Label Mapping:** `little/very/extremely_sarcastic ‚Üí Sarcastic` | `not_sarcastic ‚Üí Not Sarcastic`

**Saved Files:** `models/meme_sarcasm_model.h5`, `models/tokenizer_sarcasm.pickle`

---

### Model 6: Sentiment Classification

**Objective:** Analyze overall sentiment of memes

**Results:**

| Metric | Value |
|--------|-------|
| **Test Accuracy** | 58.10% |
| **Test Loss** | 0.6910 |
| **Precision** | 57.24% |
| **Recall** | 62.50% |
| **F1-Score** | 59.75% |

**Label Mapping:** `very_positive/positive ‚Üí Positive` | `neutral/negative/very_negative ‚Üí Non-Positive`

**Saved Files:** `models/meme_sentiment_model.h5`, `models/tokenizer_sentiment.pickle`

---

## üìä Dataset Information

### Dataset 1: Meme vs. Non-Meme Detection

**Source:** `datasets/meme_vs_not_meme_dataset/`

| Category | Dataset | Source | Images |
|----------|---------|--------|--------|
| **Meme** | Memotion Dataset 7K | [Kaggle](https://www.kaggle.com/datasets/williamscott701/memotion-dataset-7k) | ~7,000 |
| **Meme** | Memotion Test Images | [Kaggle](https://www.kaggle.com/datasets/gyanendradas/memotion?select=Test+Images) | ~1,500 |
| **Meme** | Reddit Memes Dataset | [Kaggle](https://www.kaggle.com/datasets/sayangoswami/reddit-memes-dataset) | ~5,000+ |
| **Non-Meme** | Caltech 256 Objects | [Kaggle](https://www.kaggle.com/datasets/jessicali9530/caltech256) | ~30,000+ |

**Total:** ~43,500+ images (balanced to 10,000 per class)

### Dataset 2: Meme Sentiment Analysis (Models 2-6)

**Source:** `datasets/meme_sentiment_dataset/`

| Subset | Dataset | Source | Samples | Labels |
|--------|---------|--------|---------|--------|
| **Dataset 1** | Memotion 7K (Excel) | [Kaggle](https://www.kaggle.com/datasets/williamscott701/memotion-dataset-7k) | 6,992 | Humour, Sarcasm, Offensive, Motivational, Sentiment |
| **Dataset 2** | Memotion Train (CSV) | [Kaggle](https://www.kaggle.com/datasets/gyanendradas/memotion) | 7,000 | Humour, Sarcasm, Offensive, Motivational, Sentiment |

**Total:** 13,992 labeled meme samples with OCR text extraction

---

## üöÄ Installation & Setup

### Prerequisites

- **Python:** 3.8 or higher
- **TensorFlow:** 2.15.0 (with Keras)
- **Storage:** 10-20GB free space (models + datasets)
- **RAM:** Minimum 8GB (16GB recommended)
- **GPU:** Optional but recommended (NVIDIA with CUDA support)

### Dependencies Installation

Install all required Python packages:

```bash
pip install -r requirements.txt
```

**Core Dependencies:**
```
tensorflow==2.15.0
flask==2.3.0
flask-cors==4.0.0
numpy>=1.24.0
pandas>=2.0.0
pillow>=10.0.0
scikit-learn>=1.3.0
matplotlib>=3.7.0
seaborn>=0.12.0
openpyxl>=3.1.0
easyocr>=1.7.0
```

### Verify Installation

```python
import tensorflow as tf
print(f"TensorFlow version: {tf.__version__}")
print(f"GPU available: {tf.config.list_physical_devices('GPU')}")
```

---

## üñ•Ô∏è How to Set Up the App

### Option 1: Quick Start (PowerShell Script - Recommended)

```powershell
# Navigate to project directory
cd "c:\Users\user\OneDrive\Desktop\App Projects\SentimemeNet\SentimemeNet"

# Run the start script
.\start_server.ps1
```

The script will:
1. Check for Python installation
2. Install dependencies from `requirements.txt`
3. Verify model files exist
4. Start the Flask server on `http://localhost:5000`
5. Automatically open the web interface in your browser

### Option 2: Manual Setup

```bash
# Step 1: Install dependencies
pip install -r requirements.txt

# Step 2: Verify models exist
# Ensure all .h5 model files are in the models/ folder

# Step 3: Run the Flask server
python app.py
```

### Option 3: Using Jupyter Notebooks (Training/Testing)

```bash
# Step 1: Install Jupyter
pip install jupyter notebook

# Step 2: Launch Jupyter
jupyter notebook

# Step 3: Open any notebook in the notebooks/ folder
# Example: notebooks/meme_vs_not_meme.ipynb
```

### Access the Application

Once the server is running:
- **Web Interface:** Open `http://localhost:5000` in your browser
- **API Endpoint:** `http://localhost:5000/api/analyze_meme`
- **Health Check:** `http://localhost:5000/api/health`

---

## üìñ Usage Guide

### Using the Web Interface

1. **Open the Application**
   - Navigate to `http://localhost:5000` in your web browser

2. **Upload a Meme Image**
   - **Drag & Drop:** Drag an image file into the upload area
   - **File Browse:** Click "Browse files" and select an image (JPG, PNG, GIF)
   - **Clipboard Paste:** Copy an image and paste (Ctrl+V / Cmd+V) into the upload area

3. **Add OCR Text (Optional)**
   - If the meme contains text, you can manually enter it in the text area
   - Character limit: 500 characters
   - The backend can also extract text automatically if OCR is configured

4. **Analyze the Meme**
   - Click the "Analyze Meme" button
   - Wait for processing (typically 4-6 seconds for all 6 models)
   - View real-time loading indicators

5. **View Results**
   - **Meme Detection:** Shows if the image is a meme with confidence score
   - **Sentiment Analysis:** Displays humor, motivational, offensive, sarcasm, and sentiment predictions
   - **Confidence Scores:** Visual progress bars for each prediction
   - **Processing Time:** Shows total analysis duration

6. **Export Results (Optional)**
   - Click "Export Results" to download analysis as JSON file
   - Includes all predictions, confidence scores, and metadata

### Using the API (Python)

```python
import requests
import base64

# Read and encode image
with open('path/to/meme.jpg', 'rb') as f:
    image_data = base64.b64encode(f.read()).decode('utf-8')

# Make API request
response = requests.post('http://localhost:5000/api/analyze_meme', json={
    'image': image_data,
    'ocr_text': 'Optional text from meme'  # or None
})

# Parse results
results = response.json()
if results['success']:
    print(f"Is Meme: {results['results']['meme_detection']['is_meme']}")
    print(f"Confidence: {results['results']['meme_detection']['confidence']:.2%}")
    
    if results['results']['meme_detection']['is_meme']:
        print(f"Funny: {results['results']['humour']['label']}")
        print(f"Sentiment: {results['results']['sentiment']['label']}")
        # Access other predictions...
else:
    print(f"Error: {results['error']}")
```

### Using the API (cURL)

```bash
# Convert image to base64 (Linux/Mac)
base64_image=$(base64 -w 0 your_meme.jpg)

# Make API request
curl -X POST http://localhost:5000/api/analyze_meme \
  -H "Content-Type: application/json" \
  -d "{\"image\": \"$base64_image\", \"ocr_text\": \"Your meme text\"}"
```

### Using Jupyter Notebooks (Model Training)

```python
# Example: Training the Meme Detection Model
# Open: notebooks/meme_vs_not_meme.ipynb

# Step 1: Load and preprocess datasets
meme_images = load_images_from_folder('datasets/meme_vs_not_meme_dataset/meme/')
non_meme_images = load_images_from_folder('datasets/meme_vs_not_meme_dataset/not_meme/')

# Step 2: Balance datasets
balanced_data = balance_classes(meme_images, non_meme_images, max_samples=10000)

# Step 3: Build model
model = build_mini_resnet_model(input_shape=(224, 224, 3))

# Step 4: Train model
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=15,
    callbacks=[early_stopping, model_checkpoint]
)

# Step 5: Evaluate and save
model.evaluate(test_data)
model.save('models/meme_detector_model.h5')
```

---

## üîß API Documentation

### Endpoint 1: Analyze Meme

**URL:** `POST /api/analyze_meme`

**Description:** Analyzes a meme image using all 6 deep learning models

**Request Headers:**
```
Content-Type: application/json
```

**Request Body:**
```json
{
  "image": "base64_encoded_image_string",
  "ocr_text": "optional text from meme" // or null
}
```

**Response (Meme Detected):**
```json
{
  "success": true,
  "results": {
    "meme_detection": {
      "is_meme": true,
      "confidence": 0.9253,
      "label": "Meme"
    },
    "humour": {
      "prediction": true,
      "confidence": 0.5220,
      "label": "Funny"
    },
    "motivational": {
      "prediction": false,
      "confidence": 0.6155,
      "label": "Not Motivational"
    },
    "offensive": {
      "prediction": false,
      "confidence": 0.5858,
      "label": "Not Offensive"
    },
    "sarcasm": {
      "prediction": true,
      "confidence": 0.5585,
      "label": "Sarcastic"
    },
    "sentiment": {
      "prediction": true,
      "confidence": 0.5810,
      "label": "Positive"
    },
    "ocr_text": "text extracted from meme",
    "processing_time": "4.2s"
  }
}
```

**Response (Non-Meme Detected):**
```json
{
  "success": true,
  "results": {
    "meme_detection": {
      "is_meme": false,
      "confidence": 0.8745,
      "label": "Non-Meme"
    },
    "ocr_text": "",
    "processing_time": "1.2s"
  }
}
```

**Error Response:**
```json
{
  "success": false,
  "error": "Error message description"
}
```

**Status Codes:**
- `200` - Success
- `400` - Bad Request (missing image data)
- `500` - Internal Server Error (model error)

---

### Endpoint 2: Health Check

**URL:** `GET /api/health`

**Description:** Checks backend health and model loading status

**Response:**
```json
{
  "status": "healthy",
  "models_loaded": 6,
  "tokenizers_loaded": 5
}
```

---

## üìÅ Project Structure

```
SentimemeNet/
‚îú‚îÄ‚îÄ README.md                                    # Comprehensive project documentation
‚îú‚îÄ‚îÄ requirements.txt                             # Python dependencies
‚îú‚îÄ‚îÄ app.py                                       # Flask backend server
‚îú‚îÄ‚îÄ start_server.ps1                            # Quick start PowerShell script
‚îú‚îÄ‚îÄ index.html                                   # Frontend HTML
‚îú‚îÄ‚îÄ styles.css                                   # Frontend CSS
‚îú‚îÄ‚îÄ script.js                                    # Frontend JavaScript
‚îú‚îÄ‚îÄ resnet_sample.ipynb                         # ResNet sample implementation
‚îÇ
‚îú‚îÄ‚îÄ models/                                      # Trained models
‚îÇ   ‚îú‚îÄ‚îÄ meme_detector_model.h5                  # Meme detection (92.53% acc)
‚îÇ   ‚îú‚îÄ‚îÄ meme_humour_model.h5                    # Humour classification
‚îÇ   ‚îú‚îÄ‚îÄ meme_motivational_model.h5              # Motivational classification
‚îÇ   ‚îú‚îÄ‚îÄ meme_offensive_model.h5                 # Offensive detection
‚îÇ   ‚îú‚îÄ‚îÄ meme_sarcasm_model.h5                   # Sarcasm detection
‚îÇ   ‚îú‚îÄ‚îÄ meme_sentiment_model.h5                 # Sentiment analysis
‚îÇ   ‚îú‚îÄ‚îÄ tokenizer_humour.pickle                 # Text tokenizer for humour
‚îÇ   ‚îú‚îÄ‚îÄ tokenizer_motivational.pickle           # Text tokenizer for motivational
‚îÇ   ‚îú‚îÄ‚îÄ tokenizer_offensive.pickle              # Text tokenizer for offensive
‚îÇ   ‚îú‚îÄ‚îÄ tokenizer_sarcasm.pickle                # Text tokenizer for sarcasm
‚îÇ   ‚îî‚îÄ‚îÄ tokenizer_sentiment.pickle              # Text tokenizer for sentiment
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                                   # Jupyter notebooks for training
‚îÇ   ‚îú‚îÄ‚îÄ meme_vs_not_meme.ipynb                  # Model 1: Meme detection
‚îÇ   ‚îú‚îÄ‚îÄ meme_humour_classification.ipynb        # Model 2: Humour analysis
‚îÇ   ‚îú‚îÄ‚îÄ meme_motivational_classification.ipynb  # Model 3: Motivational analysis
‚îÇ   ‚îú‚îÄ‚îÄ meme_offensive_classification.ipynb     # Model 4: Offensive detection
‚îÇ   ‚îú‚îÄ‚îÄ meme_sarcasm_classification.ipynb       # Model 5: Sarcasm detection
‚îÇ   ‚îî‚îÄ‚îÄ meme_sentiment_classification.ipynb     # Model 6: Sentiment analysis
‚îÇ
‚îú‚îÄ‚îÄ datasets/                                    # Training datasets
‚îÇ   ‚îú‚îÄ‚îÄ meme_vs_not_meme_dataset/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ meme/                               # Meme images (nested folders)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ memotion-dataset-1.5k/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ memotion-dataset-7k/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ reddit-memes-dataset/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ not_meme/                           # Non-meme images
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ 001.ak47/ ... 256.objects/      # Caltech-256 categories
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ meme_sentiment_dataset/
‚îÇ       ‚îú‚îÄ‚îÄ dataset_1/                          # Memotion 7K dataset
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ images/
‚îÇ       ‚îî‚îÄ‚îÄ dataset_2/                          # Memotion train dataset
‚îÇ           ‚îú‚îÄ‚îÄ sentiments.csv
‚îÇ           ‚îî‚îÄ‚îÄ images/
‚îÇ
‚îú‚îÄ‚îÄ prediction_test/                            # Test images for prediction
‚îú‚îÄ‚îÄ src/                                        # Source code utilities
‚îÇ   ‚îî‚îÄ‚îÄ __pycache__/
‚îî‚îÄ‚îÄ artifacts/                                  # Training artifacts
```

---

## üî¨ Technical Documentation

### Advanced Dataset Handling

**1. Multiple Dataset Support**
- Combines Excel (.xlsx) and CSV (.csv) formats
- Intelligent column mapping for different naming conventions
- Automatic format detection and parsing

**2. Image Validation & Filtering**
```python
def is_valid_image(file_path):
    """Validates image can be loaded by TensorFlow"""
    try:
        img = tf.keras.preprocessing.image.load_img(file_path)
        return True
    except:
        return False
```
- Pre-validates all images before training
- Filters corrupted or incompatible files
- Prevents runtime errors during training

**3. Automatic Class Balancing**
- Detects class imbalance automatically
- Randomly samples from majority class
- Ensures equal representation (prevents bias)
- Configurable maximum samples per class

**4. Nested Folder Support**
- Recursively scans subdirectories
- Collects images from any folder depth
- Flexible directory structure support

**5. Text Preprocessing Pipeline**
- OCR text extraction and cleaning
- Tokenization with vocabulary limit (10,000 words)
- Sequence padding to fixed length (100 tokens)
- Out-of-vocabulary (OOV) token handling

### Training Configuration

**Callbacks Used:**

**1. Early Stopping**
```python
EarlyStopping(
    monitor='val_loss',
    patience=3-5,
    restore_best_weights=True
)
```
- Prevents overfitting
- Restores best model weights
- Monitors validation loss

**2. Model Checkpoint**
```python
ModelCheckpoint(
    filepath='models/model_name.h5',
    save_best_only=True,
    monitor='val_accuracy'
)
```
- Saves best performing model
- Overwrites only when improved

**3. ReduceLROnPlateau** (Models 2-6)
```python
ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=2,
    min_lr=1e-7
)
```
- Adaptive learning rate reduction
- Improves convergence
- Prevents training plateaus

### Data Augmentation (Meme Detection)

Applied to training images only:
- **Random Rotation:** ¬±15 degrees
- **Horizontal Flip:** Random left-right flip
- **Random Contrast:** Brightness variation
- **Random Zoom:** Scale variation (¬±10%)
- **Random Translation:** Position shift

### Model Compilation

All models use:
- **Optimizer:** Adam with learning rate 0.0001
- **Loss Function:** Binary Crossentropy
- **Metrics:** Accuracy, Precision, Recall, Binary Accuracy

### Hardware Requirements

**Minimum:**
- **CPU:** Intel i5 or AMD equivalent
- **RAM:** 8GB
- **Storage:** 10GB free space
- **OS:** Windows 10+, macOS 10.14+, Ubuntu 18.04+

**Recommended:**
- **GPU:** NVIDIA GPU with CUDA support (GTX 1060 or better)
- **RAM:** 16GB or more
- **Storage:** 20GB SSD
- **Python:** 3.8-3.10

### Performance Optimization

1. **GPU Acceleration:** Enable CUDA for 10-50x faster training
2. **Batch Size Tuning:** Increase if GPU memory allows (e.g., 32, 64)
3. **Mixed Precision Training:** Use `tf.keras.mixed_precision` for faster computation
4. **Data Caching:** Cache preprocessed data in memory with `tf.data.Dataset.cache()`
5. **Multi-threading:** Use `tf.data.AUTOTUNE` for parallel processing

### Security Considerations

For production deployment:
- ‚úÖ **Rate Limiting:** Implement request throttling (e.g., 10 requests/minute)
- ‚úÖ **Authentication:** Add API keys or OAuth2 authentication
- ‚úÖ **Input Validation:** Verify image sizes (max 10MB) and formats
- ‚úÖ **HTTPS:** Configure SSL/TLS certificates
- ‚úÖ **CORS:** Restrict allowed origins in production
- ‚úÖ **Sanitization:** Escape OCR text to prevent XSS attacks
- ‚úÖ **Environment Variables:** Use `.env` files for sensitive configuration

---

## üìà Performance Summary

### Model Accuracy Comparison

| Model | Accuracy | Precision | Recall | F1-Score | Loss |
|-------|----------|-----------|--------|----------|------|
| **Meme Detection** | **92.53%** | **96.49%** | **88.49%** | **92.32%** | 0.2344 |
| Humour | 52.20% | 55.02% | 45.02% | 49.52% | 0.6898 |
| Motivational | 61.55% | 61.42% | 71.89% | 66.22% | 0.6766 |
| Offensive | 58.58% | 57.30% | 68.41% | 62.37% | 0.6922 |
| Sarcasm | 55.85% | 58.90% | 48.35% | 53.13% | 0.9760 |
| Sentiment | 58.10% | 57.24% | 62.50% | 59.75% | 0.6910 |

### Performance Insights

**‚úÖ Excellent Performance:**
- **Meme Detection** achieved 92.53% accuracy with exceptional precision (96.49%)
- Very low false positive rate makes it highly reliable
- Strong generalization across diverse meme and non-meme images

**‚ö†Ô∏è Moderate Performance:**
- Sentiment analysis models show moderate accuracy (52-62%)
- Expected due to subjective nature of humor, sarcasm, and sentiment
- Multimodal approach (image + text) significantly improves over image-only

**üéØ Key Observations:**
- **High Precision:** 96.49% precision in meme detection means very few false positives
- **Balanced Metrics:** F1-scores indicate good balance between precision and recall
- **Text Integration:** OCR text extraction aids sentiment classification
- **Class Balancing:** Automatic balancing prevents majority class bias

### Processing Time

- **Meme Detection Only:** ~1-2 seconds
- **Full Analysis (all 6 models):** ~4-6 seconds
- **Image Preprocessing:** <0.5 seconds

Times vary based on:
- Image size and complexity
- CPU/GPU availability
- System resources and load

---

## üêõ Troubleshooting

### Common Issues

**Issue 1: Models not loading**
```
Error: Unable to load model file
```
**Solution:**
- Ensure all `.h5` files exist in `models/` folder
- Check TensorFlow version compatibility (use 2.15.0)
- Verify tokenizer `.pickle` files are present
- Re-download models if corrupted

**Issue 2: Port already in use**
```
Error: Address already in use: 5000
```
**Solution:**
```powershell
# Option 1: Kill the process using port 5000
netstat -ano | findstr :5000
taskkill /PID <PID_NUMBER> /F

# Option 2: Change port in app.py
app.run(debug=True, host='0.0.0.0', port=5001)
```

**Issue 3: Frontend not connecting to backend**
```
Error: Failed to fetch
```
**Solution:**
- Verify backend is running on `http://localhost:5000`
- Check browser console for CORS errors
- Ensure `flask-cors` is installed
- Check firewall/antivirus settings

**Issue 4: Out of Memory Error**
```
ResourceExhaustedError: OOM when allocating tensor
```
**Solution:**
- Reduce batch size in training notebooks (e.g., from 16 to 8)
- Close other applications to free RAM
- Use CPU mode if GPU memory is insufficient
- Enable memory growth: `tf.config.experimental.set_memory_growth(gpu, True)`

**Issue 5: Invalid image format**
```
Error: cannot identify image file
```
**Solution:**
- Ensure images are in supported formats (.jpg, .png, .bmp, .gif)
- Check if images are corrupted (try opening in image viewer)
- Re-download datasets if necessary
- Validate images before upload (max 10MB)

**Issue 6: OCR not detecting text**
```
Warning: No text extracted from image
```
**Solution:**
- Install EasyOCR: `pip install easyocr`
- Ensure image text is clear and readable
- Try alternative OCR engine: `pip install pytesseract`
- Manually input text in the web interface

**Issue 7: Slow predictions**
```
Processing taking >30 seconds
```
**Solution:**
- First prediction may be slow (model initialization)
- Subsequent predictions are faster (~4-6s)
- Enable GPU acceleration for 10x speed improvement
- Close resource-intensive applications

**Issue 8: Module import errors**
```
ModuleNotFoundError: No module named 'tensorflow'
```
**Solution:**
- Install missing dependencies: `pip install -r requirements.txt`
- Verify Python version (3.8-3.10)
- Use virtual environment to avoid conflicts
- Reinstall TensorFlow: `pip install tensorflow==2.15.0`

---

## üìù License & Credits

### License

This project is developed as part of the **CCS 248 Final Project** at **[Your University Name]**.

**Academic Use:** Free for educational and research purposes.

**Commercial Use:** Contact the authors for licensing.

### Credits

**Project Team:**
- **Author:** JZL
- **Course:** CCS 248 - Deep Learning
- **Institution:** [Your University Name]
- **Year:** 2024

**Frameworks & Libraries:**
- **TensorFlow/Keras** - Deep learning framework
- **Flask** - Web application framework
- **Tailwind CSS** - Frontend styling
- **Feather Icons** - UI icons
- **EasyOCR** - Optical character recognition

**Datasets:**
- **Memotion Dataset 7K** - [Kaggle](https://www.kaggle.com/datasets/williamscott701/memotion-dataset-7k)
- **Memotion Test Images** - [Kaggle](https://www.kaggle.com/datasets/gyanendradas/memotion)
- **Reddit Memes Dataset** - [Kaggle](https://www.kaggle.com/datasets/sayangoswami/reddit-memes-dataset)
- **Caltech 256** - [Kaggle](https://www.kaggle.com/datasets/jessicali9530/caltech256)

### Acknowledgments

Special thanks to:
- The open-source community for providing robust tools and frameworks
- Kaggle for hosting and maintaining high-quality datasets
- The TensorFlow team for comprehensive documentation
- All researchers whose work inspired this project

### Citation

If you use this project in your research, please cite:

```bibtex
@misc{sentimemenet2024,
  author = {JZL},
  title = {SentimemeNet: A Deep Learning Approach for Meme Classification and Sentiment Analysis},
  year = {2024},
  publisher = {GitHub},
  howpublished = {\url{https://github.com/IamLevin40/SentimemeNet}}
}
```

---

## üìß Support & Contact

For issues, questions, or contributions:

1. **Check Documentation:** Review this README and troubleshooting section
2. **GitHub Issues:** Open an issue on the repository
3. **Email:** [Your Email Address]
4. **Course Forum:** Post in the CCS 248 discussion board

### Reporting Bugs

When reporting bugs, please include:
- Operating system and version
- Python version
- TensorFlow version
- Error messages and stack traces
- Steps to reproduce the issue

### Feature Requests

We welcome feature suggestions! Potential enhancements:
- [ ] Real-time video meme analysis
- [ ] Multi-language OCR support
- [ ] Batch processing for multiple memes
- [ ] Model fine-tuning interface
- [ ] Advanced visualization dashboard
- [ ] Mobile application (iOS/Android)
- [ ] API rate limiting and authentication
- [ ] Docker containerization

---

## üéì Learning Resources

### Recommended Reading

- **Deep Learning:** [Deep Learning Book by Goodfellow et al.](https://www.deeplearningbook.org/)
- **Computer Vision:** [CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/)
- **NLP:** [CS224n: Natural Language Processing with Deep Learning](http://web.stanford.edu/class/cs224n/)
- **ResNet Paper:** [Deep Residual Learning for Image Recognition (He et al., 2015)](https://arxiv.org/abs/1512.03385)
- **LSTM Paper:** [Long Short-Term Memory (Hochreiter & Schmidhuber, 1997)](https://www.bioinf.jku.at/publications/older/2604.pdf)

### Tutorials

- [TensorFlow Official Tutorials](https://www.tensorflow.org/tutorials)
- [Keras Documentation](https://keras.io/guides/)
- [Flask Mega-Tutorial](https://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world)

---

**Thank you for using SentimemeNet! üöÄ**

*Last Updated: December 10, 2025*
